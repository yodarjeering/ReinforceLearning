{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4406420b-a25c-4a6a-aceb-d0dfdf87656b",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1f15b44c-6313-42ce-8aef-c4a996e3151d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import glob\n",
    "import datetime\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(1) # (A)\n",
    "import keras.optimizers  # (B)\n",
    "from keras.models import Sequential # (C)\n",
    "from keras.layers.core import Dense, Activation #(D)\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from decimal import *\n",
    "from keras.layers.recurrent import SimpleRNN, LSTM\n",
    "from sklearn import preprocessing\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from keras.layers import Embedding\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score  \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from tensorflow.python.keras.models import load_model\n",
    "import statsmodels.graphics.api as smg\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from scipy import stats\n",
    "from scipy.stats import f\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f9ec19-a0ba-423f-ab4b-5715f621e916",
   "metadata": {},
   "source": [
    "# Load DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b07ff76a-28cb-4dd8-94a5-f0ba16cb78d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFramePreProcessing():\n",
    "\n",
    "    \n",
    "    def __init__(self, path_):\n",
    "        self.path_ = path_\n",
    "\n",
    "        \n",
    "    def load_df(self):\n",
    "        FILE = glob.glob(path_)\n",
    "        df = pd.read_csv(FILE[0])\n",
    "        df = df.rename(columns={df.columns[0]:'nan',df.columns[1]:'nan',df.columns[2]:'nan',\\\n",
    "                                    df.columns[3]:'day',df.columns[4]:'nan',df.columns[5]:'open',\\\n",
    "                                    df.columns[6]:'high',df.columns[7]:'low',df.columns[8]:'close',\\\n",
    "                                       df.columns[9]:'nan',})\n",
    "        df = df.drop('nan',axis=1)\n",
    "        df = df.drop(df.index[0])\n",
    "        df['day'] = pd.to_datetime(df['day'],format='%Y/%m/%d')\n",
    "        df.set_index('day',inplace=True)\n",
    "\n",
    "        return df.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa635950-943e-49d5-9694-596a29d7f400",
   "metadata": {},
   "source": [
    "# Make Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "55cf6389-d224-4042-87f0-a605b77dfb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MakeTrainData2class():\n",
    "    \n",
    "    \n",
    "    def __init__(self, df, stride, test_rate, column='close', scale_type='standard', is_category=True):\n",
    "        self.df = df\n",
    "        self.stride = stride # Assume stride>=1\n",
    "        self.test_rate = test_rate\n",
    "        self.column = column\n",
    "        self.scale_type = scale_type\n",
    "        self.is_category= is_category\n",
    "        \n",
    "        \n",
    "    def labeling(self):\n",
    "        if self.is_category:\n",
    "            up=1\n",
    "            down=0\n",
    "        else:\n",
    "            up=[0,1]\n",
    "            down=[1,0]\n",
    "        \n",
    "        \n",
    "        return up,down\n",
    "        \n",
    "    def make_data(self):\n",
    "        x = []\n",
    "        y = []\n",
    "        up, down = self.labeling()\n",
    "        df_column = self.df[self.column]\n",
    "        for i in range(len(df_column)-self.stride):\n",
    "            price_list = df_column.iloc[i:i+self.stride].tolist()\n",
    "            today_price = df_column.iloc[i+self.stride-1]\n",
    "            tommorow_price = df_column.iloc[i+self.stride]\n",
    "            \n",
    "            \n",
    "            if tommorow_price > today_price:# if up\n",
    "                y.append(up)\n",
    "            else: # if down or equal, but equal price is rare case.\n",
    "                y.append(down)\n",
    "                \n",
    "            \n",
    "            if self.scale_type == 'standard':\n",
    "                x.append(preprocessing.scale(np.array(price_list)).reshape(-1).tolist())\n",
    "            elif self.scale_type == 'robust':\n",
    "                x.append(preprocessing.robust_scale(np.array(price_list)).reshape(-1).tolist())\n",
    "            elif self.scale_type == 'minmax':\n",
    "                x.append(preprocessing.minmax_scale(np.array(price_list)).reshape(-1).tolist())\n",
    "                \n",
    "                \n",
    "        TEST_RATE = len(x)*self.test_rate\n",
    "        TEST_RATE = int(TEST_RATE)\n",
    "        x,y              = np.array(x),np.array(y)\n",
    "        x_train,y_train  = x[:TEST_RATE],y[:TEST_RATE]\n",
    "        x_test,y_test    = x[TEST_RATE:], y[TEST_RATE:]\n",
    "        \n",
    "        train_up_count   = y_train[y_train==up].shape[0]\n",
    "        train_down_count = y_train[y_train==down].shape[0]\n",
    "        test_up_count    = y_test[y_test==up].shape[0]\n",
    "        test_down_count  = y_test[y_test==down].shape[0]\n",
    "        print(\"Train UP :\",train_up_count,\"DOWN :\",train_down_count) # if is_one_hot, count is twice times as large as true count.\n",
    "        print(\"Test  UP :\",test_up_count,\"DOWN :\",test_down_count)\n",
    "        return x_train, y_train, x_test, y_test\n",
    "    \n",
    "    \n",
    "    def under_sampling(self):\n",
    "        x_train, y_train, x_test, y_test = self.make_data()\n",
    "        if not self.is_category:\n",
    "            y_train =  np.argmax(y_train, axis=1)\n",
    "            y_test  =  np.argmax(y_resampled, axis=1)        \n",
    "        \n",
    "        \n",
    "        x_resampled_train, y_resampled_train = self.lose_label(x_train, y_train)\n",
    "        x_resampled_test, y_resampled_test = self.lose_label(x_test, y_test)\n",
    "        train_up_count   = y_resampled_train[y_resampled_train==1].shape[0]\n",
    "        train_down_count = y_resampled_train[y_resampled_train==0].shape[0]\n",
    "        test_up_count    = y_resampled_test[y_resampled_test==1].shape[0]\n",
    "        test_down_count  = y_resampled_test[y_resampled_test==0].shape[0]\n",
    "        print(\"Train UP :\",train_up_count,\"DOWN :\",train_down_count) # if is_one_hot, count is twice times as large as true count.\n",
    "        print(\"Test  UP :\",test_up_count,\"DOWN :\",test_down_count)\n",
    "        \n",
    "        \n",
    "        if not self.is_category:\n",
    "            y_resampled_train = np.identity(2)[y_resampled_train]\n",
    "            y_resampled_test = np.identity(2)[y_resampled_test]\n",
    "\n",
    "        \n",
    "        return x_resampled_train, y_resampled_train, x_resampled_test, y_resampled_test\n",
    "        \n",
    "    def lose_label(self, x, y):\n",
    "        rus = RandomUnderSampler(random_state=0)\n",
    "        x_resampled, y_resampled = rus.fit_resample(x, y)\n",
    "        \n",
    "        return x_resampled, y_resampled\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "392b8309-34bd-4b6c-a93f-e7e91a37630a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "353caee1-f95f-4f9c-961b-611c6f5c45be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train UP : 1085 DOWN : 951\n",
      "Test  UP : 280 DOWN : 229\n"
     ]
    }
   ],
   "source": [
    "path2 = '/Users/rince/Desktop/StockPriceData/Stock_index/NFNK225_10years.csv'\n",
    "\n",
    "df_nf225 = DataFramePreProcessing.load_df(path2)\n",
    "\n",
    "x_train, y_train, x_test, y_test = MakeTrainData2class( df_nf225, stride=5, test_rate=0.8).make_data()\n",
    "# Train UP : 2170 DOWN : 1902\n",
    "# Test UP : 560 DOWN : 458\n",
    "\n",
    "# Train UP : 1085 DOWN : 951\n",
    "# Test UP : 280 DOWN : 229"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8c0306-7066-41dd-adf3-e628308b3fac",
   "metadata": {},
   "source": [
    "# Search best stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ad9e87cc-dd94-49cc-b167-bdd921fe6434",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i : 2 scale_type : standard\n",
      "Train UP : 1084 DOWN : 954\n",
      "Test  UP : 281 DOWN : 229\n",
      "Train UP : 954 DOWN : 954\n",
      "Test  UP : 229 DOWN : 229\n",
      "[22:52:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.62      0.58       229\n",
      "           1       0.55      0.46      0.50       229\n",
      "\n",
      "    accuracy                           0.54       458\n",
      "   macro avg       0.54      0.54      0.54       458\n",
      "weighted avg       0.54      0.54      0.54       458\n",
      "\n",
      "----------------------------------------\n",
      "i : 2 scale_type : robust\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train UP : 1084 DOWN : 954\n",
      "Test  UP : 281 DOWN : 229\n",
      "Train UP : 954 DOWN : 954\n",
      "Test  UP : 229 DOWN : 229\n",
      "[22:52:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.62      0.58       229\n",
      "           1       0.55      0.46      0.50       229\n",
      "\n",
      "    accuracy                           0.54       458\n",
      "   macro avg       0.54      0.54      0.54       458\n",
      "weighted avg       0.54      0.54      0.54       458\n",
      "\n",
      "----------------------------------------\n",
      "i : 2 scale_type : minmax\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train UP : 1084 DOWN : 954\n",
      "Test  UP : 281 DOWN : 229\n",
      "Train UP : 954 DOWN : 954\n",
      "Test  UP : 229 DOWN : 229\n",
      "[22:52:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.62      0.58       229\n",
      "           1       0.55      0.46      0.50       229\n",
      "\n",
      "    accuracy                           0.54       458\n",
      "   macro avg       0.54      0.54      0.54       458\n",
      "weighted avg       0.54      0.54      0.54       458\n",
      "\n",
      "----------------------------------------\n",
      "i : 4 scale_type : standard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train UP : 1084 DOWN : 952\n",
      "Test  UP : 281 DOWN : 229\n",
      "Train UP : 952 DOWN : 952\n",
      "Test  UP : 229 DOWN : 229\n",
      "[22:52:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.51      0.51       229\n",
      "           1       0.50      0.49      0.50       229\n",
      "\n",
      "    accuracy                           0.50       458\n",
      "   macro avg       0.50      0.50      0.50       458\n",
      "weighted avg       0.50      0.50      0.50       458\n",
      "\n",
      "----------------------------------------\n",
      "i : 4 scale_type : robust\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train UP : 1084 DOWN : 952\n",
      "Test  UP : 281 DOWN : 229\n",
      "Train UP : 952 DOWN : 952\n",
      "Test  UP : 229 DOWN : 229\n",
      "[22:52:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.49      0.49       229\n",
      "           1       0.50      0.51      0.50       229\n",
      "\n",
      "    accuracy                           0.50       458\n",
      "   macro avg       0.50      0.50      0.50       458\n",
      "weighted avg       0.50      0.50      0.50       458\n",
      "\n",
      "----------------------------------------\n",
      "i : 4 scale_type : minmax\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train UP : 1084 DOWN : 952\n",
      "Test  UP : 281 DOWN : 229\n",
      "Train UP : 952 DOWN : 952\n",
      "Test  UP : 229 DOWN : 229\n",
      "[22:52:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.46      0.47       229\n",
      "           1       0.49      0.51      0.50       229\n",
      "\n",
      "    accuracy                           0.49       458\n",
      "   macro avg       0.49      0.49      0.49       458\n",
      "weighted avg       0.49      0.49      0.49       458\n",
      "\n",
      "----------------------------------------\n",
      "i : 8 scale_type : standard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train UP : 1083 DOWN : 950\n",
      "Test  UP : 280 DOWN : 229\n",
      "Train UP : 950 DOWN : 950\n",
      "Test  UP : 229 DOWN : 229\n",
      "[22:52:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.48      0.49       229\n",
      "           1       0.51      0.54      0.52       229\n",
      "\n",
      "    accuracy                           0.51       458\n",
      "   macro avg       0.51      0.51      0.51       458\n",
      "weighted avg       0.51      0.51      0.51       458\n",
      "\n",
      "----------------------------------------\n",
      "i : 8 scale_type : robust\n",
      "Train UP : 1083 DOWN : 950\n",
      "Test  UP : 280 DOWN : 229\n",
      "Train UP : 950 DOWN : 950\n",
      "Test  UP : 229 DOWN : 229\n",
      "[22:52:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.46      0.49       229\n",
      "           1       0.52      0.58      0.55       229\n",
      "\n",
      "    accuracy                           0.52       458\n",
      "   macro avg       0.52      0.52      0.52       458\n",
      "weighted avg       0.52      0.52      0.52       458\n",
      "\n",
      "----------------------------------------\n",
      "i : 8 scale_type : minmax\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train UP : 1083 DOWN : 950\n",
      "Test  UP : 280 DOWN : 229\n",
      "Train UP : 950 DOWN : 950\n",
      "Test  UP : 229 DOWN : 229\n",
      "[22:52:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.52      0.49       229\n",
      "           1       0.47      0.43      0.45       229\n",
      "\n",
      "    accuracy                           0.47       458\n",
      "   macro avg       0.47      0.47      0.47       458\n",
      "weighted avg       0.47      0.47      0.47       458\n",
      "\n",
      "----------------------------------------\n",
      "i : 16 scale_type : standard\n",
      "Train UP : 1082 DOWN : 945\n",
      "Test  UP : 279 DOWN : 228\n",
      "Train UP : 945 DOWN : 945\n",
      "Test  UP : 228 DOWN : 228\n",
      "[22:52:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.45      0.44       228\n",
      "           1       0.44      0.43      0.43       228\n",
      "\n",
      "    accuracy                           0.44       456\n",
      "   macro avg       0.44      0.44      0.44       456\n",
      "weighted avg       0.44      0.44      0.44       456\n",
      "\n",
      "----------------------------------------\n",
      "i : 16 scale_type : robust\n",
      "Train UP : 1082 DOWN : 945\n",
      "Test  UP : 279 DOWN : 228\n",
      "Train UP : 945 DOWN : 945\n",
      "Test  UP : 228 DOWN : 228\n",
      "[22:52:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.54      0.51       228\n",
      "           1       0.48      0.43      0.45       228\n",
      "\n",
      "    accuracy                           0.48       456\n",
      "   macro avg       0.48      0.48      0.48       456\n",
      "weighted avg       0.48      0.48      0.48       456\n",
      "\n",
      "----------------------------------------\n",
      "i : 16 scale_type : minmax\n",
      "Train UP : 1082 DOWN : 945\n",
      "Test  UP : 279 DOWN : 228\n",
      "Train UP : 945 DOWN : 945\n",
      "Test  UP : 228 DOWN : 228\n",
      "[22:52:25] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.56      0.52       228\n",
      "           1       0.49      0.42      0.45       228\n",
      "\n",
      "    accuracy                           0.49       456\n",
      "   macro avg       0.49      0.49      0.49       456\n",
      "weighted avg       0.49      0.49      0.49       456\n",
      "\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in [2,4,8,16]:\n",
    "    for scale_type in ['standard','robust','minmax']:\n",
    "        print(\"i :\",i,\"scale_type :\",scale_type)\n",
    "        x_train, y_train, x_test, y_test = MakeTrainData2class( df_nf225, stride=i, test_rate=0.8, scale_type=scale_type).under_sampling()\n",
    "        xgb_model = xgb.XGBClassifier(use_label_encoder=False)\n",
    "        hr_pred = xgb_model.fit(x_train, y_train).predict(x_test)\n",
    "        print(classification_report(y_test, hr_pred))\n",
    "        print(\"----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "24a7f26d-1550-43c5-b746-3a6ec101a028",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:48:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.44      0.46       229\n",
      "           1       0.49      0.55      0.52       229\n",
      "\n",
      "    accuracy                           0.49       458\n",
      "   macro avg       0.49      0.49      0.49       458\n",
      "weighted avg       0.49      0.49      0.49       458\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False)\n",
    "hr_pred = xgb_model.fit(x_train, y_train).predict(x_test)\n",
    "print(classification_report(y_test, hr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f274ee85-fd4c-4048-b97e-6fa8b68d451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ = '/Users/rince/Desktop/StockPriceData/Stock_index/DAW_10years.csv'\n",
    "\n",
    "df_daw = DataFramePreProcessing.load_df(path_)\n",
    "daw_p = df_daw.pct_change()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1a7564e8-2e3c-45a8-a179-d3d8ce1acc8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-07-06</th>\n",
       "      <td>12626.02</td>\n",
       "      <td>12626.02</td>\n",
       "      <td>12626.02</td>\n",
       "      <td>12626.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-07</th>\n",
       "      <td>12719.49</td>\n",
       "      <td>12719.49</td>\n",
       "      <td>12719.49</td>\n",
       "      <td>12719.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-08</th>\n",
       "      <td>12657.20</td>\n",
       "      <td>12657.20</td>\n",
       "      <td>12657.20</td>\n",
       "      <td>12657.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-11</th>\n",
       "      <td>12505.76</td>\n",
       "      <td>12505.76</td>\n",
       "      <td>12505.76</td>\n",
       "      <td>12505.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-12</th>\n",
       "      <td>12446.88</td>\n",
       "      <td>12446.88</td>\n",
       "      <td>12446.88</td>\n",
       "      <td>12446.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-28</th>\n",
       "      <td>34283.27</td>\n",
       "      <td>34283.27</td>\n",
       "      <td>34283.27</td>\n",
       "      <td>34283.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-29</th>\n",
       "      <td>34292.29</td>\n",
       "      <td>34292.29</td>\n",
       "      <td>34292.29</td>\n",
       "      <td>34292.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-30</th>\n",
       "      <td>34502.51</td>\n",
       "      <td>34502.51</td>\n",
       "      <td>34502.51</td>\n",
       "      <td>34502.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-01</th>\n",
       "      <td>34633.53</td>\n",
       "      <td>34633.53</td>\n",
       "      <td>34633.53</td>\n",
       "      <td>34633.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-02</th>\n",
       "      <td>34786.35</td>\n",
       "      <td>34786.35</td>\n",
       "      <td>34786.35</td>\n",
       "      <td>34786.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2550 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                open      high       low     close\n",
       "day                                               \n",
       "2011-07-06  12626.02  12626.02  12626.02  12626.02\n",
       "2011-07-07  12719.49  12719.49  12719.49  12719.49\n",
       "2011-07-08  12657.20  12657.20  12657.20  12657.20\n",
       "2011-07-11  12505.76  12505.76  12505.76  12505.76\n",
       "2011-07-12  12446.88  12446.88  12446.88  12446.88\n",
       "...              ...       ...       ...       ...\n",
       "2021-06-28  34283.27  34283.27  34283.27  34283.27\n",
       "2021-06-29  34292.29  34292.29  34292.29  34292.29\n",
       "2021-06-30  34502.51  34502.51  34502.51  34502.51\n",
       "2021-07-01  34633.53  34633.53  34633.53  34633.53\n",
       "2021-07-02  34786.35  34786.35  34786.35  34786.35\n",
       "\n",
       "[2550 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nf225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b45eeaf2-e560-4058-98d2-cf2a8cc8c9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1902, 6)\n",
      "(1902,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7821b6af-b43a-45f6-b627-407ab3c8b759",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = len(x_)\n",
    "test_rate = int(0.8*length)\n",
    "\n",
    "x_train,y_train = x_[:test_rate],y_[:test_rate]\n",
    "x_test,y_test = x_[test_rate:],y_[test_rate:]\n",
    "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1])\n",
    "x_test = x_test.reshape(x_test.shape[0],x_train.shape[1])\n",
    "y_train = np.argmax(y_train,axis=1)\n",
    "y_test = np.argmax(y_test,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b642d3f7-8cc4-4ddb-9637-f3e0ad78c1c1",
   "metadata": {},
   "source": [
    "# XGB predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddb6ae0c-347a-4888-bef3-76caac060021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_pred(x_train,y_train,x_test,y_test):\n",
    "    dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "    param = {'eta': 0.09107858292565747, 'max_depth': 6, 'lambda': 0.9335155074430995, 'objective': 'multi:softmax', 'num_class': 3}  \n",
    "\n",
    "    num_round = 30\n",
    "    bst = xgb.train(param, dtrain,num_round)  \n",
    "#     bst = xgb.train(param, dtrain,num_round)  \n",
    "    # bst = xgb.train(dtrain)\n",
    "\n",
    "    dtest = xgb.DMatrix(x_test)  \n",
    "    pred = bst.predict(dtest)  \n",
    "\n",
    "    score = accuracy_score(y_test, pred)  \n",
    "    print('score:{0:.4f}'.format(score))  \n",
    "\n",
    "    #     xgb.plot_importance(bst)  \n",
    "\n",
    "    dtest = xgb.DMatrix(x_test)  \n",
    "    predict_classes = bst.predict(dtest)  \n",
    "\n",
    "    true_classes = y_test\n",
    "    plt.clf()\n",
    "    cmx = confusion_matrix(true_classes, predict_classes)\n",
    "    sns.heatmap(cmx, annot=True, fmt='g', square=True)\n",
    "    plt.show()\n",
    "    xgb.plot_importance(bst)  \n",
    "    plt.show()\n",
    "    \n",
    "    return bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f05e6ea-d324-4955-9f4a-33d80bd0acf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:26:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "score:0.5126\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bst = xgb_pred(x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1e4e19-1aec-4be3-94bf-4cfa097c66c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
